{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import các thư viện cần thiết "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.slim.nets import vgg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "source": [
    "- Resize ảnh vê kích cỡ 448x448\n",
    "- Chia thành các lưới 7x7\n",
    "- Mỗi ô vuông dự đoán 2 bounding box của đối tượng. Mỗi bounding box dự đoán có chứa object hay không.\n",
    "- Thông tin bounding box gồm có: x,y,w,h\n",
    "- Lúc cài đặt chuẩn hóa hình ảnh về kích thước \\[0-1\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Tổng hợp lại, với mỗi ô vuông chúng ta cần dữ đoán các thông tin sau :\n",
    "\n",
    "- Ô vuông có chứa đối tượng nào hay không?\n",
    "- Dự đoán độ lệch 2 box chứa object so với ô vuông hiện tại\n",
    "- Lớp của object đó Như vậy với mỗi ô vuông chúng ta cần dữ đoán một vector có (nbox+4*nbox+nclass) chiều. Ví dụ, chúng ta cần dự đoán 2 box, và 3 lớp đối với mỗi ô vuông thì chúng sẽ có một ma trận 3 chiều 7x7x13 chứa toàn bộ thông tin cần thiết."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# kích thước grid system\n",
    "cell_size = 7\n",
    "# số bounding box cần dự đoán mỗi ô vuông\n",
    "box_per_cell = 2\n",
    "# kích thước ảnh đầu vào\n",
    "img_size = 224\n",
    "# số loại nhãn\n",
    "classes = {'circle': 0, 'triangle': 1, 'rectangle':2}\n",
    "nclass = len(classes)\n",
    "\n",
    "box_scale = 5.0\n",
    "noobject_scale = 0.5\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "lr = 1e-3"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "# Load tập dữ lieeju"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    labels = json.load(open('./train/labels.json'))\n",
    "    # so luong anh\n",
    "    N = len(labels)\n",
    "    # Matrix chua anh\n",
    "    X = np.zeros((N, img_size, img_size, 3), dtype='uint8')\n",
    "    # Matrix chua nhan cua anh tuong ung\n",
    "    y = np.zeros((N, cell_size, cell_size, 5+nclass))\n",
    "    for idx, label in enumerate(labels):\n",
    "        img = cv2.imread('./train/{}.png'.format(idx))\n",
    "        # normalize ve khoang [0-1]\n",
    "        X[idx] = img\n",
    "        for box in label['boxes']:\n",
    "            x1, y1, x2, y2 = box['x1'], box['y1'], box['x2'], box['y2']\n",
    "            # one hot vector\n",
    "            cl = [0] * len(classes)\n",
    "            cl[classes[box['class']]] = 1\n",
    "            # Tam cua bounding box, chieu rong, chieu cao\n",
    "            x_center, y_center, w, h = (x1+x2)/2.0, (y1+y2)/2.0, x2-x1, y2-y1\n",
    "            # index cua object tren ma tran vuong 7x7\n",
    "            x_idx, y_idx = int(x_center/img_size * cell_size), int(y_center/img_size * cell_size)\n",
    "            # gan nhan vao matrx\n",
    "            y[idx, y_idx, x_idx] = 1, x_center, y_center, w, h, *cl\n",
    "    return X, y"
   ]
  },
  {
   "source": [
    "# Chia tập dữ liệu thành train/val"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=28091997)"
   ]
  },
  {
   "source": [
    "# Định nghĩa mô hình CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Đầu ra mô hình: SxSx(nbox+4*nbox+nclass)\n",
    "- Với S = 7, mỗi ô dự đoán B=2 boxes, nclass = 3 thì output có shape = 7x7x13"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(inputs, is_training):\n",
    "    \"\"\" Định nghĩa CNN\n",
    "    Args:\n",
    "        inputs: 5-D tensor [batch_size, width, height, 3]\n",
    "    return:\n",
    "        iou: 4-D tensor [batch_size, 7, 7, 5*nbox + nclass]\n",
    "    \"\"\"\n",
    "    # khái báo scope để có thể group những biến liên quan cho việc visualize trên tensorboard\n",
    "    with tf.variable_scope(\"vgg_16\"):\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "            # hàm repeat có tác dụng lặp lại tầng conv2d n lần mà không phải định nghĩa phức tạp\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 16, [3,3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 32, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            # Thay vì sử dụng 2 tầng FC tại đây\n",
    "            # Chúng ta sử dụng conv với kernel_size = (1,1) có tác dụng giống FC\n",
    "            net = slim.conv2d(net, 512, [1,1], scope='fc6')\n",
    "            net = slim.conv2d(net, 13, [1,1], activation_fn=None, scope='fc7')\n",
    "    return net"
   ]
  },
  {
   "source": [
    "# Hàm tính IOU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2, scope='iou'):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
    "        boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                             boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                             boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        # calculate the left up point & right down point\n",
    "        lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "        rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "        # intersection\n",
    "        intersection = tf.maximum(0.0, rd - lu)\n",
    "        inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "        # calculate the boxs1 square and boxs2 square\n",
    "        square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "        square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)"
   ]
  },
  {
   "source": [
    "# Loss function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "YOLO sử dụng hàm độ lỗi bình phương giữ dự đoán và nhãn để tính độ lỗi cho mô hình. Cụ thể, độ lỗi tổng của chúng ta sẽ là tổng của 3 độ lỗi con sau:\n",
    "\n",
    "- Độ lỗi của việc dữ đoán loại nhãn của object - Classifycation loss\n",
    "- Độ lỗi của dự đoán tạo độ cũng như chiều dài, rộng của boundary box - Localization loss\n",
    "- Độ lỗi của ô vuông có chứa object nào hay không - Confidence loss\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Chúng ta mong muốn hàm lỗi có chức năng sau. Trong quá trình huấn luyện, mô hình sẽ nhìn vào những ô vuông có chứa object. Tăng classification score lớp đúng của object đó lên. Sau đó, cũng nhìn vào ô vuông đó, tìm boundary box tốt nhất trong 2 boxes được dự đoán. Tăng localization score của boundary box đó lên, thay đổi thông tin boundary box để gần đúng với nhãn. Đối với những ô vuông không chứa object, giảm confidence score và chúng ta sẽ không quan tâm đến classification score và localization score của những ô vuông này."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_layer(predicts, labels, scope='loss_layer'):\n",
    "    \"\"\"calculate loss function\n",
    "    Args:\n",
    "      predicts: 4-D tensor [batch_size, 7, 7, 5*nbox+n_class] \n",
    "      labels: 4-D tensor [batch_size, 7, 7, 5+n_class]\n",
    "    Return:\n",
    "      loss: scalar\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(cell_size)] * cell_size * box_per_cell),\n",
    "            (box_per_cell, cell_size, cell_size)), (1, 2, 0))\n",
    "        offset = offset[None, :]\n",
    "        offset = tf.constant(offset, dtype=tf.float32)\n",
    "        offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "        \n",
    "        # 2 phần tử đầu của vector dự đoán tại một ô vuông là confidence score\n",
    "        predict_object = predicts[..., :box_per_cell]\n",
    "        \n",
    "        # 8 phần tử tiếp theo là dự đoán offset của boundary box và width height\n",
    "        predict_box_offset = tf.reshape(predicts[...,box_per_cell:5*box_per_cell], (-1, cell_size, cell_size, box_per_cell, 4))\n",
    "        \n",
    "        # các phần tử cuối là dự đoán lớp của object\n",
    "        predict_class = predicts[...,5*box_per_cell:]\n",
    "        \n",
    "        # chuyển vị trí offset về toạ độ normalize trên khoảng [0-1]\n",
    "        predict_normalized_box = tf.stack(\n",
    "                                    [(predict_box_offset[..., 0] + offset) / cell_size,\n",
    "                                     (predict_box_offset[..., 1] + offset_tran) / cell_size,\n",
    "                                     tf.square(predict_box_offset[..., 2]),\n",
    "                                    tf.square(predict_box_offset[..., 3])], axis=-1)\n",
    "\n",
    "        # lấy các nhãn tương ứng \n",
    "        true_object = labels[..., :1]\n",
    "        true_box = tf.reshape(labels[..., 1:5], (-1, cell_size, cell_size, 1, 4))\n",
    "        \n",
    "        # để normalize tọa độ pixel về đoạn [0-1] chúng ta chia cho img_size (224)\n",
    "        true_normalized_box = tf.tile(true_box, (1, 1, 1, box_per_cell, 1))/img_size\n",
    "        true_class = labels[..., 5:]\n",
    "        \n",
    "        # tính vị trí offset từ nhãn \n",
    "        true_box_offset =  tf.stack(\n",
    "                                    [true_normalized_box[..., 0] * cell_size - offset,\n",
    "                                     true_normalized_box[..., 1] * cell_size - offset_tran,\n",
    "                                     tf.sqrt(true_normalized_box[..., 2]),\n",
    "                                     tf.sqrt(true_normalized_box[..., 3])], axis=-1)\n",
    "        \n",
    "        # tính iou\n",
    "        predict_iou = compute_iou(true_normalized_box, predict_normalized_box)\n",
    "        \n",
    "        # mask chứa vị trí các ô vuông chứa object\n",
    "        object_mask = tf.reduce_max(predict_iou, 3, keepdims=True)  \n",
    "        \n",
    "        # tính metric để monitor \n",
    "        iou_metric = tf.reduce_mean(tf.reduce_sum(object_mask, axis=[1,2,3])/tf.reduce_sum(true_object, axis=[1,2,3]))\n",
    "        \n",
    "        object_mask = tf.cast((predict_iou>=object_mask), tf.float32)*true_object\n",
    "\n",
    "        noobject_mask = tf.ones_like(object_mask) - object_mask\n",
    "        \n",
    "        ## class loss\n",
    "        class_delta = true_object*(predict_class - true_class)\n",
    "        class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1,2,3]), name='class_loss')\n",
    "        \n",
    "        ## object loss\n",
    "        object_delta = object_mask*(predict_object - predict_iou)\n",
    "        object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1,2,3]), name='object_loss')\n",
    "        \n",
    "        ## noobject loss\n",
    "        noobject_delta = noobject_mask*predict_object\n",
    "        noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1,2,3]), name='noobject_loss')\n",
    "        \n",
    "        ## coord loss\n",
    "        box_mask = tf.expand_dims(object_mask, 4)\n",
    "        box_delta = box_mask*(predict_box_offset - true_box_offset)\n",
    "        box_loss = tf.reduce_mean(tf.reduce_sum(tf.square(box_delta), axis=[1,2,3]), name='box_loss')\n",
    "        \n",
    "        loss = 0.5*class_loss + object_loss + 0.1*noobject_loss + 10*box_loss\n",
    "        \n",
    "        return loss, iou_metric, predict_object, predict_class, predict_normalized_box"
   ]
  },
  {
   "source": [
    "# Biên dịch graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'img_size' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e549a380f0ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# None đại diện cho batch_size, giúp batch_size có thể thay đổi linh hoạt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_size' is not defined"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    # None đại diện cho batch_size, giúp batch_size có thể thay đổi linh hoạt\n",
    "    images = tf.placeholder(\"float\", [None, img_size, img_size, 3], name=\"input\")\n",
    "    labels = tf.placeholder('float', [None, cell_size, cell_size, 8], name='label')\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "    logits = vgg16(images, is_training)\n",
    "    loss, iou_metric, predict_object, predict_class, predict_normalized_box = loss_layer(logits, labels)\n",
    "    \n",
    "    # định nghĩa adam optimizer, để tối ưu hàm loss\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Định nghĩa saver để lưu lại trọng số của mô hình, dùng trong test ảnh mới\n",
    "    saver = tf.train.Saver(max_to_keep=1)\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch in range(len(X_train)//batch_size):\n",
    "            # Lấy tùng batch, forward, backward, cập nhật trọng số theo adam\n",
    "            X_batch = X_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "\n",
    "            train_total_loss, train_iou_m, _ = sess.run([loss, iou_metric, train_op], {images: X_batch, labels: y_batch, is_training: True})\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Tính toán loss, iou trên tập validation\n",
    "        val_loss = []\n",
    "        val_iou_ms = []\n",
    "        for batch in range(len(X_test)//batch_size):\n",
    "            val_X_batch = X_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            val_y_bacth = y_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            total_val_loss, val_iou_m, val_predict_object, val_predict_class, val_predict_normalized_box = sess.run([loss, iou_metric, predict_object, predict_class, predict_normalized_box], {images: val_X_batch, labels: val_y_bacth, is_training:False})\n",
    "            val_loss.append(total_val_loss)\n",
    "            val_iou_ms.append(val_iou_m)\n",
    "        saver.save(sess, './yolo_{}'.format(epoch), global_step=epoch)\n",
    "        print('epoch: {} - running_time: {:.0f}s - train_loss: {:.3f} - train_iou: {:.3f} - val_loss: {:.3f} - val_iou: {:.3f}'.format(epoch, end_time - start_time, train_total_loss, train_iou_m, np.mean(val_loss), np.mean(val_iou_ms)))"
   ]
  },
  {
   "source": [
    "# Hiển thị kết quả dự đoán\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Fillter tất cả các box không thỏa mãn điều kiện như không chứa object, mert các box overlap nhiều."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    \"\"\" tính iou bằng numpy \n",
    "    Args:\n",
    "      box1: [center_x, center_y, w, h] \n",
    "      box2: [center_x, center_y, w, h] \n",
    "    Return:\n",
    "      iou: iou\n",
    "    \"\"\"\n",
    "    tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\n",
    "        max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\n",
    "    lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\n",
    "        max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\n",
    "    inter = 0 if tb < 0 or lr < 0 else tb * lr\n",
    "    return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\n",
    "    \n",
    "def interpret_output(predict_object, predict_class, predict_normalized_box):\n",
    "    # nhận lại img-size để ra không gian pixel\n",
    "    predict_box= predict_normalized_box*img_size\n",
    "    predict_object = np.expand_dims(predict_object, axis=-1)\n",
    "    predict_class = np.expand_dims(predict_class, axis=-2)\n",
    "    # xác suất ô boundary chứa class bằng boundary chứa object * xác suất có điều kiện của lớp đó mà ô vuông chứa object\n",
    "    class_probs = predict_object*predict_class\n",
    "    \n",
    "    # giữ các boundary box mà có xác suất chứa lớp >= 0.2\n",
    "    filter_mat_probs = np.array(class_probs >= 0.2, dtype='bool')\n",
    "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "    boxes_filtered = predict_box[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "    class_probs_filtered = class_probs[filter_mat_probs]\n",
    "    \n",
    "    # chọn index của lớp có xác xuất lớp nhất lại mỗi boundary box\n",
    "    classes_num_filtered = np.argmax(\n",
    "        filter_mat_probs, axis=3)[\n",
    "        filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "\n",
    "    # giữ lại boundary box dự đoán có xác xuất lớp nhất\n",
    "    argsort = np.array(np.argsort(class_probs_filtered))[::-1]\n",
    "    boxes_filtered = boxes_filtered[argsort]\n",
    "    class_probs_filtered = class_probs_filtered[argsort]\n",
    "    classes_num_filtered = classes_num_filtered[argsort]\n",
    "\n",
    "    # thuật toán non-maximun suppression\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        if class_probs_filtered[i] == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, len(boxes_filtered)):\n",
    "            if iou(boxes_filtered[i], boxes_filtered[j]) > 0.5:\n",
    "                class_probs_filtered[j] = 0.0\n",
    "                \n",
    "    # filter bước cuối bỏ những boundary overlap theo thuật toán trên\n",
    "    filter_iou = np.array(class_probs_filtered > 0.0, dtype='bool')\n",
    "    boxes_filtered = boxes_filtered[filter_iou]\n",
    "    class_probs_filtered = class_probs_filtered[filter_iou]\n",
    "    classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        result.append(\n",
    "            [classes_num_filtered[i],\n",
    "             boxes_filtered[i][0],\n",
    "             boxes_filtered[i][1],\n",
    "             boxes_filtered[i][2],\n",
    "             boxes_filtered[i][3],\n",
    "             class_probs_filtered[i]])\n",
    "\n",
    "    return result\n",
    "\n",
    "def draw_result(img, result):\n",
    "    \"\"\" hiển thị kết quả dự đoán\n",
    "    Args:\n",
    "      img: ảnh      \n",
    "      result: giá trị sinh ra ở hàm trên    \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10), dpi=40)\n",
    "    img = np.pad(img, [(50,50), (50,50), (0,0)], mode='constant', constant_values=255)\n",
    "    for i in range(len(result)):\n",
    "        x = int(result[i][1])+50\n",
    "        y = int(result[i][2])+50\n",
    "        w = int(result[i][3] / 2)\n",
    "        h = int(result[i][4] / 2)\n",
    "        cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (231, 76, 60), 2)\n",
    "        cv2.rectangle(img, (x - w, y - h - 20),\n",
    "                      (x -w + 50, y - h), (46, 204, 113), -1)\n",
    "        cv2.putText(\n",
    "            img, '{} : {:.2f}'.format(result[i][0] ,result[i][5]),\n",
    "            (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "            (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'val_predict_object' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e38f0feb9639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpret_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_predict_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_predict_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_predict_normalized_box\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_predict_object' is not defined"
     ]
    }
   ],
   "source": [
    "img_idx = 15\n",
    "result = interpret_output(val_predict_object[img_idx], val_predict_class[img_idx], val_predict_normalized_box[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'val_X_batch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b7982ae53ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_X_batch' is not defined"
     ]
    }
   ],
   "source": [
    "draw_result(val_X_batch[img_idx]*255, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}